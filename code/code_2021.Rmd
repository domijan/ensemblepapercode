---
title: "Analysis with Ensambles: 14 traits data (absorbance values)"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




```{r echo = FALSE, message=FALSE, warning= FALSE}
rm(list = ls())
set.seed(1979)
library(tidyverse)
library(dendextend)
library(glmnet)
library(pls)
library(ranger)
library(bartMachine)
library(e1071)
library(BKPC)
library(kernlab)
library(caret) 
library(effects)
library(stats)
library(lme4)
library(brnn)
library(gbm)
kfunc <-  rbfdot(sigma = 0.0005)
```

```{r echo = FALSE, message=FALSE, warning= FALSE, eval = FALSE}

a <- read.csv("data/2021/recleaneddataset1.csv")


y_names <- c(
  "kappa_casein",
  "alpha_s2_casein",
  "alpha_s1_casein",
  "beta_casein",
  "alpha_lactalbumin",
  "beta_lactoglobulin_a",
  "beta_lactoglobulin_b",
  "Casein_micelle_size",
  "Heat_stability",
  "Native_pH",
  "RCT",
  "k20",
  "a30",
  "a60"
)

ys <- a |> select(y_names)
x <- a[, 60:590]

calcRMSE <- function(y, yhat) {
  sqrt(mean((yhat - y)^2))
}

ys[, 8] <- log(ys[, 8])
a <- apply(ys, 2, mean, na.rm = TRUE)
b <- apply(ys, 2, sd, na.rm = TRUE)

ys <- sweep(ys, 2, a, "-")
ys <- sweep(ys, 2, b, "/")
id_te <- sample(nrow(x), 69)
ys_te <- ys[id_te, ]
te <- x[id_te, ]
ys_tr <- ys[-id_te, ]
tr <- x[-id_te, ]

me <- apply(tr, 2, mean)
sd <- apply(tr, 2, sd)

tr <- scale(tr, me, sd)
te <- scale(te, me, sd)

```




```{r echo = FALSE, message=FALSE, warning= FALSE, eval = FALSE}


indexcor <- abs(cor(cbind(ys_tr, tr), use = "pairwise.complete.obs"))[1:14, -c(1:14)]

# clustering the columns (variables) rather than observations
D2 <- as.matrix(1 - abs(cor(tr)))



h2 <- hclust(as.dist(D2), method = "ward.D2")
dnew <- as.dendrogram(h2)
d2 <- color_branches(dnew, k = 15, col = 2:16)
labl.cols <- cutree(d2, 15) # 15 variables
nonz <- matrix(0, 14, 15)
for (j in unique(labl.cols)) {
  for (i in 1:14) {
    nonz[i, j] <- (which(indexcor[i, ] == max(indexcor[i, labl.cols == j])))
  }
}
```


## Ensemble classifiers



* MA: model averaging
* Stack: regression
* Stack: non negative coefficients
* Stack: lasso
* Stack: RF and all the predictors


### Crossvalidation set up

* Split the data into training and testing (200 observations for the training), the rest for testing, 50 random splits. 

* 10 fold cross - validation on each of the 50 training sets to train stack. 


```{r echo = FALSE, message=FALSE, warning= FALSE, eval = FALSE}

N <- 50
grid <- 10^seq(-3, 3, length = 100)
RMSEFULL <- vector(mode = "list", length = 20)
t1 <- vector(mode = "list", length = 14)
names(t1) <- names(ys_tr)
flds <- createFolds(1:200, k = 10, list = TRUE, returnTrain = FALSE)


pls.pc <- c(4, 6, 5, 4, 3, 6, 15, 4, 10, 15, 8, 4, 8, 7)

lm.fit.SG <- replicate(14, vector(mode = "list", length = N))
nonneg.fit.SG <- replicate(14, vector(mode = "list", length = N))
rf.fit.SG <- replicate(14, vector(mode = "list", length = N))
lasso.fit.SG <- replicate(14, vector(mode = "list", length = N))


for (yind in 1:14) {
  dat <- cbind(ys_tr[, yind], tr)

  dat <- as.data.frame(dat)
  dat <- dat |> na.omit()

  nonzy <- nonz[yind, ]

  set.seed(1979)
  ttt <- replicate(N, sample(nrow(dat), 200))


  RMSE <- matrix(0, N, 20)
  predictions.te <- matrix(0, nrow(dat) - 200, 15)
  predictions.tv <- matrix(0, 200, 15)



  for (i in 1:N) {
    dat.tr.full <- dat[ttt[, i], ]
    dat.te <- dat[-ttt[, i], ]

    for (l in 1:10) {
      dat.tr <- dat.tr.full[-flds[[l]], ]
      dat.tv <- dat.tr.full[flds[[l]], ]

      j <- 1
      x <- model.matrix(V1 ~ ., data = dat.tr)
      y1 <- dat.tr[, 1]

      set.seed(1951)
      lasso.fit <- glmnet(x, y1, alpha = 1, lambda = grid) 
      cv.out <- cv.glmnet(x, y1, alpha = 1)


      set.seed(1951)
      lasso.fit <- glmnet(x, y1,
        alpha = 1,
        lambda = cv.out$lambda.min
      )


      lasso.pred <- predict(lasso.fit, 
                            newx = model.matrix(V1 ~ ., data = dat.tv))
      predictions.tv[flds[[l]], j] <- lasso.pred
      j <- j + 1

      #############################################

      set.seed(1951)
      en.fit <- glmnet(x, y1, alpha = 0.5, lambda = grid) 

      cv.out <- cv.glmnet(x, y1, alpha = 0.5)

      set.seed(1951)
      en.fit <- glmnet(x, y1,
        alpha = 0.5,
        lambda = cv.out$lambda.min
      )


      en.pred <- predict(en.fit, 
                         newx = model.matrix(V1 ~ ., 
                                                     data = dat.tv))
      predictions.tv[flds[[l]], j] <- en.pred
      j <- j + 1


      ####################################################
      set.seed(1951)
      pc <- prcomp(dat.tr[, 2:ncol(dat.tr)], scale = TRUE)

      pca.lm.fit <- lm(dat.tr[, 1] ~ pc$x[, 1:5])

      x.tv <- predict(pc, dat.tv[, 2:ncol(dat.tr)])
      pca.pred <- as.matrix(cbind(rep(1, nrow(x.tv)), x.tv[, 1:5])) %*%
        as.matrix(pca.lm.fit$coef[1:6])

      predictions.tv[flds[[l]], j] <- pca.pred
      j <- j + 1

      #############################################################

      set.seed(1951)
      pls.fit <- plsr(V1 ~ ., 
                      data = dat.tr, 
                      scale = TRUE, 
                      validation = "CV")


      pls.pred <- predict(pls.fit, 
                          dat.tv[, -1],
                          ncomp = pls.pc[yind])

      predictions.tv[flds[[l]], j] <- pls.pred
      j <- j + 1


      #############################################################
      set.seed(1951)
      lm.fit <- lm(dat.tr[, 1] ~ as.matrix(dat.tr[, nonzy + 1]))
      x <- model.matrix(V1 ~ ., data = dat.tv[, c(1, nonzy + 1)])
      lm.pred <- x %*% as.matrix(lm.fit$coef)


      predictions.tv[flds[[l]], j] <- lm.pred
      j <- j + 1

      #############################################################
      set.seed(1951)

      rf.fit <- ranger(V1 ~ ., 
                       data = dat.tr, 
                       importance = "impurity")
      pred.rf <- predict(rf.fit, data = dat.tv)

      predictions.tv[flds[[l]], j] <- pred.rf$predictions
      j <- j + 1

      ####################################################
      set.seed(1951)
      rf.vs.fit <- ranger(V1 ~ ., 
                          data = dat.tr, 
                          importance = "impurity", 
                          regularization.factor = 0.2,
                          regularization.usedepth = FALSE)
      pred.vs.rf <- predict(rf.vs.fit, data = dat.tv)

      predictions.tv[flds[[l]], j] <- pred.vs.rf$predictions
      j <- j + 1

      ####################################################
      set.seed(1951)
      bart.fit <- bartMachine(as.data.frame(dat.tr[, -1]), 
                              dat.tr[, 1], 
                              verbose = FALSE)
      pred.bart <- predict(bart.fit, as.data.frame(dat.tv[, -1]))
      predictions.tv[flds[[l]], j] <- pred.bart
      j <- j + 1

      ####################################################
      set.seed(1951)
      Ktrain <- kernelMatrix(kfunc, 
                             as.matrix(dat.tr[, 2:ncol(dat.tr)]))
      Kvalid <- kernelMatrix(kfunc, 
                             as.matrix(dat.tv[, 2:ncol(dat.tr)]),
                             as.matrix(dat.tr[, 2:ncol(dat.tr)]))
      kpcTrain <- kPCA(Ktrain)


      kpcValid <- predict(kpcTrain, Kvalid)
      kpca.lm.fit <- lm(dat.tr[, 1] ~ kpcTrain$KPCs[, 1:6])

      kpca.pred <- cbind(rep(1, nrow(kpcValid)), kpcValid[, 1:6]) %*%
        as.matrix(kpca.lm.fit$coef)


      predictions.tv[flds[[l]], j] <- kpca.pred
      j <- j + 1


      ####################################################
      set.seed(1951)

      rf.kpc.fit <- ranger(y = dat.tr[, 1], 
                           x = kpcTrain$KPCs[, 1:6], 
                           importance = "impurity")
      pred.rf.kpc <- predict(rf.kpc.fit, 
                             data = kpcValid[, 1:6])
      
      predictions.tv[flds[[l]], j] <- pred.rf.kpc$predictions
      j <- j + 1


      ####################################################
      set.seed(1951)
      rf.k.fit <- ranger(y = dat.tr[, 1], 
                         x = Ktrain, 
                         importance = "impurity")
      pred.rf.k <- predict(rf.k.fit, data = Kvalid)
      predictions.tv[flds[[l]], j] <- pred.rf.k$predictions
      j <- j + 1


      ####################################################
      set.seed(1951)
      svm.fit <- svm(V1 ~ ., dat.tr)

      # Predict using SVM regression
      pred.svm <- predict(svm.fit, dat.tv)
      predictions.tv[flds[[l]], j] <- pred.svm
      j <- j + 1



      ####################################################
      set.seed(1951)
      ppr.fit <- ppr(dat.tr[, -1], 
                     dat.tr[, 1], 
                     nterms = 2, 
                     max.terms = 5)
      pred.ppr <- ppr.fit |> 
        predict(dat.tv[, -1])

      predictions.tv[flds[[l]], j] <- pred.ppr
      j <- j + 1

      ####################################################
      set.seed(1951)
      brnn.fit <- brnn(as.matrix(dat.tr[, -1]), dat.tr[, 1])
      pred.brnn <- brnn.fit |> predict(dat.tv[, -1]) 
      predictions.tv[flds[[l]], j] <- pred.brnn
      j <- j + 1


      ####################################################
      set.seed(1951)
      gbm.fit <- gbm(V1 ~ ., 
                     data = dat.tr, 
                     distribution = "gaussian", 
                     cv.folds = 5, 
                     n.trees = 200)
      best.iter <- gbm.perf(gbm.fit, method = "cv")

      pred.gbm <- gbm.fit |> predict(dat.tv[, -1], 
                                     n.trees = best.iter)
      predictions.tv[flds[[l]], j] <- pred.gbm
      j <- j + 1
    }


    colnames(predictions.tv) <- c("lasso", "elastic net", "pca", "pls", "LM+15", "RF", "RF+VS", "Bart", "kPCA", "RF+kPCA", "RF+kernel", "svm", "ppr", "brnn", "gbm")


    ####################################################
    set.seed(1951)
    lm.fit.SG[[i]][[yind]] <- lm(dat.tr.full[, 1] ~ predictions.tv - 1)
    ####################################################
    set.seed(1951)
    nonneg.fit.SG[[i]][[yind]] <- glmnet(predictions.tv, 
                                         dat.tr.full[, 1], 
                                         alpha = 1, 
                                         lambda = 0, 
                                         lower.limits = 0, 
                                         intercept = FALSE)
    ####################################################
    set.seed(1951)
    rf.fit.SG[[i]][[yind]] <- ranger(y = dat.tr.full[, 1], 
                                     x = cbind(predictions.tv,
                                               dat.tr.full[, -1]),
                                     importance = "impurity")
    ####################################################
    set.seed(1951)
    cv.out <- cv.glmnet(predictions.tv, 
                        dat.tr.full[, 1], 
                        alpha = 1, 
                        lambda = grid, 
                        intercept = FALSE)

    lasso.fit.SG[[i]][[yind]] <- glmnet(predictions.tv, 
                                        dat.tr.full[, 1], 
                                        alpha = 1, 
                                        lambda = cv.out$lambda.min,
                                        intercept = FALSE)

    j <- 1
    ####################################################
    set.seed(1951)
    x <- model.matrix(V1 ~ ., data = dat.tr.full)
    y1 <- dat.tr.full[, 1]
    lasso.fit <- glmnet(x, y1, alpha = 1, lambda = grid) 
    cv.out <- cv.glmnet(x, y1, alpha = 1)

    lasso.fit <- glmnet(x, y1,
      alpha = 1,
      lambda = cv.out$lambda.min
    )


    lasso.pred <- predict(lasso.fit, 
                          newx = model.matrix(V1 ~ ., data = dat.te))
    RMSE[i, j] <- calcRMSE(dat.te[, 1], lasso.pred)
    predictions.te[, j] <- lasso.pred
    j <- j + 1

    #############################################

    set.seed(1951)
    en.fit <- glmnet(x, y1, alpha = 0.5, lambda = grid) # for lasso

    cv.out <- cv.glmnet(x, y1, alpha = 0.5)
  
    en.fit <- glmnet(x, y1,
      alpha = 0.5,
      lambda = cv.out$lambda.min
    )


    en.pred <- predict(en.fit, 
                       newx = model.matrix(V1 ~ ., data = dat.te))
    RMSE[i, j] <- calcRMSE(dat.te[, 1], en.pred)
    predictions.te[, j] <- en.pred
    j <- j + 1

    ####################################################

    set.seed(1951)
    pc <- prcomp(dat.tr.full[, 2:ncol(dat.tr.full)], scale = TRUE)

    pca.lm.fit <- lm(dat.tr.full[, 1] ~ pc$x[, 1:5])

    x.te <- predict(pc, dat.te[, 2:ncol(dat.tr.full)])
    pca.pred <- as.matrix(cbind(rep(1, nrow(x.te)), x.te[, 1:5])) %*%
      as.matrix(pca.lm.fit$coef[1:6])

    RMSE[i, j] <- calcRMSE(dat.te[, 1], pca.pred)
    predictions.te[, j] <- pca.pred
    j <- j + 1

    #############################################################

    set.seed(1951)

    pls.fit <- plsr(V1 ~ ., 
                    data = dat.tr.full, 
                    scale = TRUE, 
                    validation = "CV")


    pls.pred <- predict(pls.fit, 
                        dat.te[, -1], 
                        ncomp = pls.pc[yind])

    RMSE[i, j] <- calcRMSE(dat.te[, 1], 
                           pls.pred)
    predictions.te[, j] <- pls.pred
    j <- j + 1


    #############################################################
    set.seed(1951)
    lm.fit <- lm(dat.tr.full[, 1] ~ as.matrix(dat.tr.full[, nonzy + 1]))
    x <- model.matrix(V1 ~ ., data = dat.te[, c(1, nonzy + 1)])
    lm.pred <- x %*% as.matrix(lm.fit$coef)


    RMSE[i, j] <- calcRMSE(dat.te[, 1], lm.pred)
    predictions.te[, j] <- lm.pred
    j <- j + 1

    #############################################################


    set.seed(1951)
    rf.fit <- ranger(V1 ~ ., 
                     data = dat.tr.full, 
                     importance = "impurity")
    pred.rf <- predict(rf.fit, data = dat.te)

    RMSE[i, j] <- calcRMSE(dat.te[, 1], pred.rf$predictions)
    predictions.te[, j] <- pred.rf$predictions
    j <- j + 1
    #############################################################


    set.seed(1951)


    rf.vs.fit <- ranger(V1 ~ ., 
                        data = dat.tr.full, 
                        importance = "impurity", 
                        regularization.factor = 0.2,
                        regularization.usedepth = FALSE)
    pred.rf.vs <- predict(rf.vs.fit, data = dat.te)

    RMSE[i, j] <- calcRMSE(dat.te[, 1], pred.rf.vs$predictions)
    predictions.te[, j] <- pred.rf.vs$predictions
    j <- j + 1

    #############################################################


    set.seed(1951)


    bart.fit <- bartMachine(as.data.frame(dat.tr.full[, -1]),
                            dat.tr.full[, 1], 
                            verbose = FALSE)
    pred.bart <- predict(bart.fit, 
                         as.data.frame(dat.te[, -1]))
    RMSE[i, j] <- calcRMSE(dat.te[, 1], 
                           pred.bart)
    predictions.te[, j] <- pred.bart
    j <- j + 1


    #############################################################


    set.seed(1951)

    Ktrain <- kernelMatrix(kfunc, 
                           as.matrix(dat.tr.full[, 2:ncol(dat.tr.full)]))
    Ktest <- kernelMatrix(kfunc, 
                          as.matrix(dat.te[, 2:ncol(dat.tr.full)]),
                          as.matrix(dat.tr.full[, 2:ncol(dat.tr.full)]))
    kpcTrain <- kPCA(Ktrain)



    kpcTest <- predict(kpcTrain, Ktest)
    kpca.lm.fit <- lm(dat.tr.full[, 1] ~ kpcTrain$KPCs[, 1:6])

    kpca.pred <- cbind(rep(1, nrow(kpcTest)), kpcTest[, 1:6]) %*%
      as.matrix(kpca.lm.fit$coef)



    RMSE[i, j] <- calcRMSE(dat.te[, 1], kpca.pred)
    predictions.te[, j] <- kpca.pred
    j <- j + 1



    #############################################################
    set.seed(1951)

    rf.kpca.fit <- ranger(y = dat.tr.full[, 1], 
                          x = kpcTrain$KPCs[, 1:6], 
                          importance = "impurity")

    pred.rf.kpca <- predict(rf.kpca.fit, data = kpcTest[, 1:6])

    RMSE[i, j] <- calcRMSE(dat.te[, 1], 
                           pred.rf.kpca$predictions)
    predictions.te[, j] <- pred.rf.kpca$predictions
    j <- j + 1

    #############################################################
    set.seed(1951)

    rf.k.fit <- ranger(y = dat.tr.full[, 1], 
                       x = Ktrain, 
                       importance = "impurity")
    pred.rf.k <- predict(rf.k.fit, data = Ktest)

    RMSE[i, j] <- calcRMSE(dat.te[, 1], pred.rf.k$predictions)
    predictions.te[, j] <- pred.rf.k$predictions
    j <- j + 1


    #############################################################
    set.seed(1951)
    svm.fit <- svm(V1 ~ ., dat.tr.full)

    pred.svm <- predict(svm.fit, dat.te)
    RMSE[i, j] <- calcRMSE(dat.te[, 1], pred.svm)
    predictions.te[, j] <- pred.svm
    j <- j + 1
    #############################################################
    set.seed(1951)
    ppr.fit <- ppr(dat.tr.full[, -1], 
                   dat.tr.full[, 1], 
                   nterms = 2, 
                   max.terms = 5)
    pred.ppr <- ppr.fit |> 
      predict(dat.te[, -1])
    RMSE[i, j] <- calcRMSE(dat.te[, 1], pred.ppr)
    predictions.te[, j] <- pred.ppr
    j <- j + 1

    #############################################################
    set.seed(1951)
    brnn.fit <- brnn(as.matrix(dat.tr.full[, -1]), dat.tr.full[, 1])
    pred.brnn <- brnn.fit |> predict(dat.te[, -1])
    RMSE[i, j] <- calcRMSE(dat.te[, 1], pred.brnn)
    predictions.te[, j] <- pred.brnn
    j <- j + 1

    #############################################################
    set.seed(1951)
    gbm.fit <- gbm(
      V1 ~ .,
      data = dat.tr.full,
      distribution = "gaussian",
      cv.folds = 5,
      n.trees = 200
    )

    best.iter <- gbm.perf(gbm.fit, method = "cv")

    pred.gbm <- gbm.fit |> 
      predict(dat.te[, -1], 
              n.trees = best.iter)
    RMSE[i, j] <- calcRMSE(dat.te[, 1], pred.gbm)
    predictions.te[, j] <- pred.gbm
    j <- j + 1

    RMSE[i, j] <- calcRMSE(dat.te[, 1], 
                           rowMeans(predictions.te[, 1:15]))


    colnames(predictions.te) <- c("lasso", "elastic net", "pca", "pls", "LM+15", "RF", "RF+VS", "Bart", "kPCA", "RF+kPCA", "RF+kernel", "svm", "ppr", "brnn", "gbm")


    pred.stack.lm <- as.matrix(predictions.te) %*% as.matrix(lm.fit.SG[[i]][[yind]]$coef)

    pred.stack.nonneg <- predict(nonneg.fit.SG[[i]][[yind]], predictions.te)

    pred.stack.rf <- predict(rf.fit.SG[[i]][[yind]], data = cbind(predictions.te, dat.te[, -1]))$prediction

    pred.stack.lasso <- predict(lasso.fit.SG[[i]][[yind]], predictions.te)



    RMSE[i, j + 1] <- calcRMSE(dat.te[, 1], pred.stack.lm)
    RMSE[i, j + 2] <- calcRMSE(dat.te[, 1], pred.stack.nonneg)
    RMSE[i, j + 3] <- calcRMSE(dat.te[, 1], pred.stack.rf)
    RMSE[i, j + 4] <- calcRMSE(dat.te[, 1], pred.stack.lasso)
  }

  colnames(RMSE) <- c("lasso", "elastic net", "pca", "pls", "LM+15", "RF", "RF+VS", "Bart", "kPCA", "RF+kPCA", "RF+kernel", "svm", "ppr", "brnn", "gbm", "ensamble MA", "ensLM", "ensNonNeg", "ensRF", "enslasso")

  RMSEFULL[[yind]] <- RMSE

  RMSE1 <- RMSE |>
    as.data.frame() |>
    mutate(split = as.factor(1:N)) |>
    pivot_longer(1:20, "ALGORITHM")



  t1[[yind]] <- RMSE1 |>
    group_by(ALGORITHM) |>
    summarise(meanv = mean(value), sdv = sd(value)) |>
    arrange(desc(meanv))
}


save.image("analysisEnsambles2c2021.Rdata")
```

```{r echo = FALSE}
load("data/2021/analysisEnsambles2c2021Hamilton.Rdata")

RMSEFULLDF <- matrix(0, 1000 * 14, 3) |>
  as.data.frame() |>
  mutate(trait = rep(names(ys), each = 1000))


for (yind in 1:14) {
  colnames(RMSEFULL[[yind]]) <- c(
    "LASSO", "EN", "PCA", "PLS", "LM+15", "RF",
    "RF+VS", "BART", "kPCA", "RF+kPCA", "RF+kernel", 
    "SVM", "PPR", "BRNN",
    "GBM", "Ens_MA", "Ens_LM", "Ens_nonneg", "Ens_RF", "Ens_LASSO"
  )
  a <- (yind - 1) * 1000 + 1
  b <- yind * 1000
  d <- (yind - 1) * 50 + 1
  e <- yind * 50
  RMSE <- RMSEFULL[[yind]]
  RMSE1 <- RMSE |>
    as.data.frame() |>
    mutate(split = d:e) |>
    pivot_longer(1:20, "ALGORITHM")
  RMSEFULLDF[a:b, 1:3] <- RMSE1
}
names(RMSEFULLDF) <- c("Split", "Algorithm", "RMSE", "Trait")

RMSEFULLDF <- RMSEFULLDF |> 
  mutate(Split = as.factor(Split), 
         Algorithm = as.factor(Algorithm), 
         Trait = as.factor(Trait))

RMSEFULLDF <- RMSEFULLDF |> 
  filter(Algorithm != "PPR")
```


```{r}
RMSEkappa <- RMSEFULLDF |> 
  filter(Trait == "kappa_casein")
RMSEkappa |>
  ggplot(aes(x = reorder(Algorithm, RMSE), 
             y = RMSE, group = Split, 
             col = Split)) +
  geom_line(show.legend = FALSE) +
  xlab("") +
  ggtitle("kappa_casein") +
  theme(axis.text.x = element_text(angle = 90))
```

## Fit mixed model to results: 



```{r echo = TRUE}
data.nest1.lmer <- lmer(RMSE ~ Algorithm * Trait + 
                          (1 | Split), 
                        RMSEFULLDF, 
                        REML = TRUE)
```


Using effects package, the error bars are estimate $\pm 1.96 \times$ se.

```{r echo = FALSE}
library(effects)
data.nest1.eff <- effect("Algorithm:Trait", data.nest1.lmer) |>
  as.data.frame()
data.nest1.eff <- data.nest1.eff |> 
  mutate(nonneg = as.numeric(Algorithm == "ensNonNeg"))


data.nest1.eff |>
  ggplot(aes(y = fit, x = Trait, 
             group = Algorithm, 
             colour = Algorithm)) +
  geom_pointrange(aes(
    ymin = lower,
    ymax = upper
  )) +
  ylab("RMSE") +
  theme(axis.text.x = element_text(angle = 90)) +
  geom_line(aes(alpha = nonneg), show.legend = FALSE) +
  ylim(0.5, 1.4)
```


```{r echo = FALSE, fig.height=10, fig.width= 10}

data.nest1.eff |> 
  ggplot(aes(y = fit, x = Algorithm)) +
  geom_errorbar(aes(
    ymin = lower,
    ymax = upper, colour = nonneg
  ), show.legend = FALSE) +
  scale_y_continuous("RMSE") +
  theme(axis.text.x = element_text(angle = 90)) +
  facet_wrap(~Trait)
```


```{r echo = FALSE}
data.nest1.eff <- as.data.frame(Effect("Algorithm", data.nest1.lmer))

data.nest1.eff |> 
  ggplot(aes(y = fit, x = reorder(Algorithm, fit))) +
  geom_pointrange(aes(
    ymin = lower,
    ymax = upper
  )) +
  ylab("RMSE") +
  xlab("method") +
  theme(axis.text.x = element_text(angle = 90)) +
  geom_point(size = 3, pch = 1) +
  ylim(0.8, 0.95)
```
